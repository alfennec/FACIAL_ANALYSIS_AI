# FACIAL_ANALYSIS_AI

### Citing Our Work

If you find Our repository useful in your research, please consider citing our paper:

```
@article{Berrahal2022,
abstract = {The advancements in artificial intelligence research, particularly in computer vision, have led to the development of previously unimaginable applications, such as generating new contents based on text description. In our work we focused on the text-to-image synthesis applications (TIS) field, to transform descriptive sentences into a real image. To tackle this issue, we use unsupervised deep learning networks that can generate high quality images from text descriptions, provided by eyewitnesses to assist law enforcement in their investigations, for the purpose of generating probable human faces. We analyzed a number of existing approaches and chose the best one. Deep fusion generative adversarial networks (DF-GAN) is the network that performs better than its peers, at multiple levels, like the generated image quality or the respect of the giving descriptive text. Our model is trained on the CelebA dataset and text descriptions (generated by our algorithm using existing attributes in the dataset). The obtained results from our implementation show that the learned generative model makes excellent quantitative and visual performances, the model is capable of generating realistic and diverse samples for human faces and create a complete portrait with respect of given text description.},
author = {Berrahal, Mohammed and Azizi, Mostafa},
doi = {10.11591/IJEECS.V25.I2.PP972-979},
file = {:C\:/Users/BERRAHAL MOHAMMED/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berrahal, Azizi - 2022 - Optimal text-to-image synthesis model for generating portrait images using generative adversarial network techn.pdf:pdf},
issn = {2502-4760},
journal = {Indonesian Journal of Electrical Engineering and Computer Science},
keywords = {Deep fusion,Deep fusion-GAN,Deep learning,GAN,Generative adversarial network,Portrait generation,Text-to-image synthesis},
month = {feb},
number = {2},
pages = {972--979},
title = {{Optimal text-to-image synthesis model for generating portrait images using generative adversarial network techniques}},
url = {http://ijeecs.iaescore.com/index.php/IJEECS/article/view/26824},
volume = {25},
year = {2022}
}
```

```
@inproceedings{Berrahal2022,
abstract = {Nowadays, we are experiencing the emergence of intelligent applications, capable of recognizing a human face by using shape, gender, face attributes or even emotions. Those application are deployed in numerous real-world sites, like facial recognition systems, Law enforcement applications or security purposes. For these reasons, we propose to improve available facial attributes' estimation in the main model, by adding other attributes, such as (medical-mask or face cover, head scarf, tattoo) and using transfer learning (TL). To do this end, using TL one stage, we suggest retraining the main model on new attributes all at once, and using TL multistage training, where we employ a TL network for each attribute. The main model is trained on the CelebA dataset with 40 attributes using a CNN model, while for the aforementioned three attributes, we use our constructed dataset. The obtained results show that the second method outruns the first in terms of metrics, but the first one is better in prediction rates, especially for the attributes of the main model, this is a problem caused by many TL networks losing data.},
author = {Berrahal, Mohammed and Azizi, Mostafa},
doi = {10.1109/iraset52964.2022.9737845},
isbn = {9781665422093},
month = {mar},
pages = {1--7},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Improvement of facial attributes' estimation using Transfer Learning}},
year = {2022}
}
```

```
@article{Berrahal2021,
abstract = {Both human face recognition and generation by machines are currently an active area of computer vision, drawing curiosity of researchers, capable of performing amazing image analysis, and producing applications in multiple domains. In this paper, we propose a new approach for face attributes classification (FAC) taking advantage from both binary classification and data augmentation. With binary classification we can reach high prediction scores, while augmented data prevent overfitting and overcome the lack of data for sketched photos. Our approach, named Augmented binary multilabel CNN (ABM-CNN), consists of three steps: i) splitting data; ii) transformed-it to sketch (simplification process); iii) train separately each attribute with two convolutional neural networks; the whole process includes two networks: the first (resp. the second) one is to predict attributes on real images (resp. sketches) as inputs. Through experimentation, we figure out that some attributes give high prediction rates with sketches rather than with real images. On the other hand, we build a new face dataset, more consistent and complete, by generating images using Style-GAN model, to which we apply our method for extracting face attributes. As results, our proposal demonstrates more performances compared to those of related works.},
author = {Berrahal, Mohammed and Azizi, Mostafa},
doi = {10.11591/IJEECS.V23.I2.PP973-979},
file = {:C\:/Users/BERRAHAL MOHAMMED/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Berrahal, Azizi - 2021 - Augmented binary multi-labeled CNN for practical facial attribute classification.pdf:pdf},
issn = {2502-4760},
journal = {Indonesian Journal of Electrical Engineering and Computer Science},
keywords = {CNN,Data augmentation,Deep learning,Face attributes,Face sketch image,Image classification,Multi,Multi-label learning,label learning},
month = {aug},
number = {2},
pages = {973--979},
title = {{Augmented binary multi-labeled CNN for practical facial attribute classification}},
url = {http://ijeecs.iaescore.com/index.php/IJEECS/article/view/24782},
volume = {23},
year = {2021}
}
```

```
@inproceedings{Berrahal2020,
abstract = {Artificial Intelligence (AI) reached various domains in our daily problems, among them is aiding law enforcement in identifying suspects by generating face images or retrieving their images from existing databases, based on the description of witnesses. The existing methods like hand-drawn sketches take time and absorb human resources; in addition to that rendering images from the software fails most of the time to sketch a real image and does not get the ideal scenario. In this paper, we present a survey of the recent progress concerning generating images from description and sketch face recognition, we analyze the difference between several algorithms on the problem based on evaluation metrics like accuracy and correlation similarity. We also give an overview of datasets used for generations or recognition.},
author = {Berrahal, Mohammed and Azizi, Mostafa},
booktitle = {4th International Conference on Intelligent Computing in Data Sciences, ICDS 2020},
doi = {10.1109/ICDS50568.2020.9268710},
isbn = {9781728180847},
keywords = {Composite Face,Deep Learning,Generative Adversarial Networks,Image Generation,Sketch Face},
mendeley-groups = {AR04},
month = {nov},
pages = {1--8},
publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
title = {{Review of DL-Based Generation Techniques of Augmented Images using Portraits Specification}},
year = {2020}
}
```
